{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "url_pages = []\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'http://www.ettoday.net/news/news-list-2016-04-{}-0-{}.htm'\n",
    "for d in xrange(1,30):\n",
    "#當月日期迴圈\n",
    "    for j in xrange(1,30):\n",
    "        url_pages.append(url.format(d,j))\n",
    "#當日頁碼迴圈\n",
    "#並將網頁都存進 url_pages陣列\n",
    "#print url_pages\n",
    "\n",
    "for url_page in url_pages:\n",
    "    #從陣列中取出網址\n",
    "    res = requests.get(url_page)\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    list_item = soup.select('#all-news-list h3')\n",
    "    #抓出所有新聞時間、標題、連結資訊\n",
    "    for li in list_item:\n",
    "        \n",
    "        #print url_page.split('-')[4]\n",
    "        rr = url_page.split('-')[4]\n",
    "        rrr =int(rr)\n",
    "        date = li.select('span')[0].text\n",
    "        dd = date[4:6]\n",
    "        ddd =int(dd)\n",
    "        #print ddd\n",
    "        \n",
    "        time.sleep(0.6)\n",
    "        if (ddd != rrr):\n",
    "            break\n",
    "        #條件判斷: 去除多餘的資料重複\n",
    "        \n",
    "        \n",
    "        print li.select('span')[0].text.strip(), li.select('a')[0].text.strip() , 'http://star.ettoday.net/news/' +str(li.select('a')[0]['href']).split('/')[-1][:-4]\n",
    "         #新聞時間、標題、連結\n",
    "        \n",
    "        t=li.select('span')[0].text.strip()\n",
    "        url = 'http://star.ettoday.net/news/' +str(li.select('a')[0]['href']).split('/')[-1][:-4]\n",
    "        res = requests.get(url)\n",
    "        soup = BeautifulSoup(res.text)\n",
    "        p = soup.select(\".story p\")\n",
    "        #抓出新聞內文\n",
    "        \n",
    "        #for i in p:\n",
    "        #    print i.text\n",
    "            \n",
    "        name= str(li.select('a')[0]['href']).split('/')[-1][:-4] \n",
    "        #抓檔案名稱\n",
    "\n",
    "        f = open('/Users/BIG DATA/Desktop/news/{}.text'.format(name),'w')\n",
    "        f.write(t.encode('utf-8') +'\\n')\n",
    "        #寫入時間\n",
    "        f.write(li.select('a')[0].text.strip().encode('utf-8') +'\\n')\n",
    "        #寫入標題\n",
    "        f.write(li.select('em')[0].text.strip().encode('utf-8') +'\\n')\n",
    "        #寫入分類\n",
    "        f.write('http://star.ettoday.net/news/' +str(li.select('a')[0]['href']).split('/')[-1][:-4].encode('utf-8') +'\\n')\n",
    "        #寫入網址\n",
    "        for i in p:\n",
    "            f.write(i.text.encode('utf-8'))\n",
    "            #寫入內文\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
